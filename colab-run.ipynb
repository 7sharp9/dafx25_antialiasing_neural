{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti-Aliasing Neural Network Training on Google Colab\n",
    "\n",
    "This notebook enables GPU-accelerated training of anti-aliasing RNN models.\n",
    "\n",
    "**Expected speedup:** 20-30x (from 32 min/epoch on CPU to ~1-2 min/epoch on T4 GPU)\n",
    "\n",
    "## Setup Overview\n",
    "\n",
    "1. Mount Google Drive for persistent storage\n",
    "2. Clone repository from GitHub\n",
    "3. Install dependencies\n",
    "4. Create symlinks for weights/audio/checkpoints\n",
    "5. Configure wandb for remote monitoring\n",
    "6. Run training\n",
    "\n",
    "## Before Running\n",
    "\n",
    "Ensure your Google Drive has this structure:\n",
    "```\n",
    "Google Drive/\n",
    "└── AA_Neural/\n",
    "    ├── weights/\n",
    "    │   └── NAM/\n",
    "    │       └── Marshall JCM 800 2203/\n",
    "    │           └── JCM800 2203 - P5 B5 M5 T5 MV7 G10 - AZG - 700.nam\n",
    "    ├── audio_data/\n",
    "    │   └── val_input.wav\n",
    "    └── checkpoints/\n",
    "        (created automatically)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive\n",
    "\n",
    "This mounts your Google Drive to `/content/drive` for persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\nimport os\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# Verify the AA_Neural folder exists\ndrive_base = '/content/drive/MyDrive/AA_Neural'\nassert os.path.exists(drive_base), f\"ERROR: {drive_base} not found. Create it and upload weights/audio_data first.\"\nassert os.path.exists(f'{drive_base}/weights'), f\"ERROR: {drive_base}/weights not found.\"\nassert os.path.exists(f'{drive_base}/audio_data'), f\"ERROR: {drive_base}/audio_data not found.\"\n\nprint(\"\\u2713 Google Drive mounted successfully\")\nprint(f\"\\u2713 Found {drive_base}\")\nprint(f\"\\u2713 Found {drive_base}/weights\")\nprint(f\"\\u2713 Found {drive_base}/audio_data}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Clone Repository\n\nClone the repository from GitHub. Update the URL below with your repo.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\n\n# Configuration\nREPO_URL = 'https://github.com/YOUR_USERNAME/dafx25_antialiasing_neural.git'  # UPDATE THIS\nREPO_DIR = '/content/dafx25_antialiasing_neural'\n\n# Remove existing clone if present\nif os.path.exists(REPO_DIR):\n    print(f\"Removing existing {REPO_DIR}\")\n    !rm -rf {REPO_DIR}\n\n# Clone repository\nprint(f\"Cloning {REPO_URL}...\")\n!git clone --recurse-submodules {REPO_URL} {REPO_DIR}\n\n# Change to repo directory\nos.chdir(REPO_DIR)\nprint(f\"\\n\\u2713 Repository cloned to {REPO_DIR}\")\nprint(f\"\\u2713 Current directory: {os.getcwd()}\")\n\n# Verify OpenAmp submodule\nassert os.path.exists('OpenAmp/Open_Amp/amp_model.py'), \"ERROR: OpenAmp submodule not loaded correctly\"\nprint(\"\\u2713 OpenAmp submodule loaded\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Install Dependencies\n\nInstall required Python packages. Colab already has PyTorch, so we only install additional dependencies.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Install core dependencies\n!pip install -q pytorch-lightning wandb auraloss neural-amp-modeler librosa\n\n# Verify critical imports\nimport torch\nimport pytorch_lightning as pl\nimport wandb\n\nprint(\"\\u2713 Dependencies installed\")\nprint(f\"\\u2713 PyTorch version: {torch.__version__}\")\nprint(f\"\\u2713 PyTorch Lightning version: {pl.__version__}\")\nprint(f\"\\u2713 CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"\\u2713 GPU: {torch.cuda.get_device_name(0)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Link Drive Storage\n",
    "\n",
    "Create symlinks so the training script reads weights/audio from Drive and saves checkpoints to Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport shutil\n\ndrive_base = '/content/drive/MyDrive/AA_Neural'\nrepo_dir = '/content/dafx25_antialiasing_neural'\n\n# Ensure we're in the repo directory\nos.chdir(repo_dir)\n\n# Create symlinks for persistent storage\nsymlinks = [\n    ('weights', f'{drive_base}/weights'),\n    ('audio_data', f'{drive_base}/audio_data'),\n    ('lightning_logs', f'{drive_base}/checkpoints'),  # Redirect PL checkpoints\n]\n\nfor link_name, target in symlinks:\n    link_path = f'{repo_dir}/{link_name}'\n    \n    # Remove existing file/dir/symlink\n    if os.path.islink(link_path):\n        os.unlink(link_path)\n    elif os.path.isdir(link_path):\n        shutil.rmtree(link_path)\n    elif os.path.exists(link_path):\n        os.remove(link_path)\n    \n    # Create target directory if it doesn't exist\n    os.makedirs(target, exist_ok=True)\n    \n    # Create symlink\n    os.symlink(target, link_path)\n    print(f\"\\u2713 Linked {link_name} -> {target}\")\n\n# Verify critical files exist\ntest_file = 'weights/NAM/Marshall JCM 800 2203/JCM800 2203 - P5 B5 M5 T5 MV7 G10 - AZG - 700.nam'\nassert os.path.exists(test_file), f\"ERROR: {test_file} not found. Check that Drive has weights/NAM/Marshall JCM 800 2203/ directory.\"\nprint(f\"\\u2713 Verified model file accessible: {test_file}\")\n\ntest_audio = 'audio_data/val_input.wav'\nassert os.path.exists(test_audio), f\"ERROR: {test_audio} not found. Check that Drive has audio_data/val_input.wav file.\"\nprint(f\"\\u2713 Verified audio file accessible: {test_audio}\")\n\nprint(f\"\\u2713 Checkpoints will save to {drive_base}/checkpoints\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Configure wandb\n\nLogin to Weights & Biases for experiment tracking. Get your API key from https://wandb.ai/authorize",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import wandb\n\n# Login to wandb\n# Option 1: Interactive login (will prompt for API key)\nwandb.login()\n\n# Option 2: Programmatic login (uncomment and add your key)\n# wandb.login(key='your-api-key-here')\n\nprint(\"\\u2713 wandb configured\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Training Configuration\n\nSet training parameters. Modify these as needed.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Training configuration\nCONFIG_IDX = 3          # Model config (3 = JCM800 NAM model)\nMAX_EPOCHS = 100        # Number of epochs to train\nUSE_WANDB = True        # Enable wandb logging\n\nprint(f\"Training configuration:\")\nprint(f\"  Config index: {CONFIG_IDX}\")\nprint(f\"  Max epochs: {MAX_EPOCHS}\")\nprint(f\"  wandb logging: {USE_WANDB}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Run Training\n\nExecute the training script. Progress will stream to this notebook.\n\n**Expected time:** ~2-3 hours for 100 epochs on T4 GPU\n\n**Monitoring:** \n- Live metrics visible in this notebook\n- Full dashboard at wandb.ai\n- Checkpoints auto-save to Drive",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\n\n# Ensure we're in the repo directory\nos.chdir('/content/dafx25_antialiasing_neural')\n\n# Build command\ncmd_parts = [\n    'python train.py',\n    f'--config {CONFIG_IDX}',\n    f'--max_epochs {MAX_EPOCHS}',\n]\n\nif USE_WANDB:\n    cmd_parts.append('--wandb')\nelse:\n    cmd_parts.append('--no-wandb')\n\ncmd = ' '.join(cmd_parts)\n\nprint(f\"Executing: {cmd}\")\nprint(\"=\"*80)\n\n# Run training (this will take a while)\n!{cmd}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Post-Training\n\nAfter training completes, checkpoints are in Google Drive.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# List saved checkpoints\nimport os\nimport glob\n\ncheckpoints_base = '/content/drive/MyDrive/AA_Neural/checkpoints'\n\n# Find all checkpoint versions\nversions = sorted(glob.glob(f'{checkpoints_base}/version_*'))\n\nif versions:\n    latest_version = versions[-1]\n    print(f\"Found {len(versions)} training run(s)\")\n    print(f\"\\nLatest run: {latest_version}\")\n    \n    # List checkpoints in latest run\n    checkpoints = glob.glob(f'{latest_version}/checkpoints/*.ckpt')\n    if checkpoints:\n        print(f\"\\nCheckpoints ({len(checkpoints)}):\")\n        for ckpt in sorted(checkpoints):\n            size_mb = os.path.getsize(ckpt) / (1024*1024)\n            print(f\"  {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n    \n    # Check for best model export\n    best_export = f'{latest_version}/best_export'\n    if os.path.exists(best_export):\n        print(f\"\\n✓ Best model exported to: {best_export}\")\n        exported_files = glob.glob(f'{best_export}/*')\n        for f in exported_files:\n            print(f\"  {os.path.basename(f)}\")\nelse:\n    print(\"No checkpoints found. Training may not have completed.\")\n\nprint(f\"\\nAll results saved to Google Drive: {checkpoints_base}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}