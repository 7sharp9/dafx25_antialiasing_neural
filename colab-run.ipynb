{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j0s8yUxLcvd"
      },
      "source": [
        "# Anti-Aliasing Neural Network Training on Google Colab\n",
        "\n",
        "This notebook enables GPU-accelerated training of anti-aliasing RNN models.\n",
        "\n",
        "**Expected speedup:** 20-30x (from 32 min/epoch on CPU to ~1-2 min/epoch on T4 GPU)\n",
        "\n",
        "## Setup Overview\n",
        "\n",
        "1. Mount Google Drive for persistent storage\n",
        "2. Clone repository from GitHub\n",
        "3. Install dependencies\n",
        "4. Create symlinks for weights/audio/checkpoints\n",
        "5. Configure wandb for remote monitoring\n",
        "6. Run training\n",
        "\n",
        "## Before Running\n",
        "\n",
        "Ensure your Google Drive has this structure:\n",
        "```\n",
        "Google Drive/\n",
        "└── AA_Neural/\n",
        "    ├── weights/\n",
        "    │   └── NAM/\n",
        "    │       └── Marshall JCM 800 2203/\n",
        "    │           └── JCM800 2203 - P5 B5 M5 T5 MV7 G10 - AZG - 700.nam\n",
        "    ├── audio_data/\n",
        "    │   └── val_input.wav\n",
        "    └── checkpoints/\n",
        "        (created automatically)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLKfssm3Lcvi"
      },
      "source": [
        "## Quick Start\n",
        "\n",
        "**First time setup:**\n",
        "1. Update `REPO_URL` in cell 2 with your GitHub repository URL\n",
        "2. Run all cells in order (Runtime → Run all)\n",
        "3. Authenticate Google Drive when prompted\n",
        "4. Enter wandb API key when prompted\n",
        "\n",
        "**Subsequent runs:**\n",
        "- Just run all cells again\n",
        "- Previous checkpoints remain in Drive\n",
        "\n",
        "**Monitor training:**\n",
        "- Live metrics appear below each cell\n",
        "- Visit wandb.ai dashboard for full visualization\n",
        "- Can close this tab - training continues, checkpoints save to Drive\n",
        "\n",
        "**Troubleshooting:**\n",
        "- If Drive mount fails: Runtime → Reset all runtimes, try again\n",
        "- If out of memory: Reduce batch_size in config.py\n",
        "- If session disconnects: Re-run notebook, checkpoints in Drive are preserved"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49c0737",
      "metadata": {},
      "source": [
        "## 1. Mount Google Drive\n",
        "\n",
        "This mounts your Google Drive to `/content/drive` for persistent storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdpzfxffLcvj",
        "outputId": "4cbe6157-2108-4b1d-f83d-eb6c26efcba4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Check if Drive is already accessible\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    print(\"Drive already mounted\")\n",
        "else:\n",
        "    # Clean up /content/drive if it exists but isn't mounted\n",
        "    if os.path.exists('/content/drive'):\n",
        "        import shutil\n",
        "        shutil.rmtree('/content/drive')\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Verify the AA_Neural folder exists\n",
        "drive_base = '/content/drive/MyDrive/AA_Neural'\n",
        "assert os.path.exists(drive_base), f\"ERROR: {drive_base} not found. Create it and upload weights/audio_data first.\"\n",
        "assert os.path.exists(f'{drive_base}/weights'), f\"ERROR: {drive_base}/weights not found.\"\n",
        "assert os.path.exists(f'{drive_base}/audio_data'), f\"ERROR: {drive_base}/audio_data not found.\"\n",
        "\n",
        "print(\"\\u2713 Google Drive mounted successfully\")\n",
        "print(f\"\\u2713 Found {drive_base}\")\n",
        "print(f\"\\u2713 Found {drive_base}/weights\")\n",
        "print(f\"\\u2713 Found {drive_base}/audio_data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DKy4bYOLcvl"
      },
      "source": [
        "## 2. Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH-k36PKLcvl",
        "outputId": "9ed1914f-8732-4eb0-caab-d092944bfcb8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Configuration\n",
        "REPO_URL = 'https://github.com/7sharp9/dafx25_antialiasing_neural.git'\n",
        "REPO_DIR = '/content/dafx25_antialiasing_neural'\n",
        "\n",
        "# Remove existing clone if present\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(f\"Removing existing {REPO_DIR}\")\n",
        "    !rm -rf {REPO_DIR}\n",
        "\n",
        "# Clone repository\n",
        "print(f\"Cloning {REPO_URL}...\")\n",
        "!git clone --recurse-submodules {REPO_URL} {REPO_DIR}\n",
        "\n",
        "# Change to repo directory\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"\\n\\u2713 Repository cloned to {REPO_DIR}\")\n",
        "print(f\"\\u2713 Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify OpenAmp submodule\n",
        "assert os.path.exists('OpenAmp/Open_Amp/amp_model.py'), \"ERROR: OpenAmp submodule not loaded correctly\"\n",
        "print(\"\\u2713 OpenAmp submodule loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjvxAZwELcvm"
      },
      "source": [
        "## 3. Install Dependencies\n",
        "\n",
        "Install required Python packages. Colab already has PyTorch, so we only install additional dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-UhaqyeLcvm",
        "outputId": "e56c461e-a5f0-48f3-89ef-5f8d3cdfc872"
      },
      "outputs": [],
      "source": [
        "# Install core dependencies\n",
        "!pip install -q pytorch-lightning wandb auraloss neural-amp-modeler librosa torchcodec\n",
        "\n",
        "# Verify critical imports\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import wandb\n",
        "\n",
        "print(\"\\u2713 Dependencies installed\")\n",
        "print(f\"\\u2713 PyTorch version: {torch.__version__}\")\n",
        "print(f\"\\u2713 PyTorch Lightning version: {pl.__version__}\")\n",
        "print(f\"\\u2713 CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\u2713 GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgpW1QAzLcvm"
      },
      "source": [
        "## 4. Link Drive Storage\n",
        "\n",
        "Create symlinks so the training script reads weights/audio from Drive and saves checkpoints to Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEfUHG5oLcvn",
        "outputId": "c690659c-425c-4744-bf9b-0d8c56c612bd"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "drive_base = '/content/drive/MyDrive/AA_Neural'\n",
        "repo_dir = '/content/dafx25_antialiasing_neural'\n",
        "\n",
        "# Ensure we're in the repo directory\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "# Create symlinks for persistent storage\n",
        "symlinks = [\n",
        "    ('weights', f'{drive_base}/weights'),\n",
        "    ('audio_data', f'{drive_base}/audio_data'),\n",
        "    ('lightning_logs', f'{drive_base}/checkpoints'),  # Redirect PL checkpoints\n",
        "]\n",
        "\n",
        "for link_name, target in symlinks:\n",
        "    link_path = f'{repo_dir}/{link_name}'\n",
        "\n",
        "    # Remove existing file/dir/symlink\n",
        "    if os.path.islink(link_path):\n",
        "        os.unlink(link_path)\n",
        "    elif os.path.isdir(link_path):\n",
        "        shutil.rmtree(link_path)\n",
        "    elif os.path.exists(link_path):\n",
        "        os.remove(link_path)\n",
        "\n",
        "    # Create target directory if it doesn't exist\n",
        "    os.makedirs(target, exist_ok=True)\n",
        "\n",
        "    # Create symlink\n",
        "    os.symlink(target, link_path)\n",
        "    print(f\"\\u2713 Linked {link_name} -> {target}\")\n",
        "\n",
        "# Verify critical files exist\n",
        "test_file = 'weights/NAM/Marshall JCM 800 2203/JCM800 2203 - P5 B5 M5 T5 MV7 G10 - AZG - 700.nam'\n",
        "assert os.path.exists(test_file), f\"ERROR: {test_file} not found. Check that Drive has weights/NAM/Marshall JCM 800 2203/ directory.\"\n",
        "print(f\"\\u2713 Verified model file accessible: {test_file}\")\n",
        "\n",
        "test_audio = 'audio_data/val_input.wav'\n",
        "assert os.path.exists(test_audio), f\"ERROR: {test_audio} not found. Check that Drive has audio_data/val_input.wav file.\"\n",
        "print(f\"\\u2713 Verified audio file accessible: {test_audio}\")\n",
        "\n",
        "print(f\"\\u2713 Checkpoints will save to {drive_base}/checkpoints\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4681vxXLcvn"
      },
      "source": [
        "## 5. Configure wandb\n",
        "\n",
        "Login to Weights & Biases for experiment tracking. Get your API key from https://wandb.ai/authorize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezldLPfOLcvn",
        "outputId": "b72ae3fe-6bd4-4f31-e9fe-481c4c2d612e"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to wandb\n",
        "# Option 1: Interactive login (will prompt for API key)\n",
        "wandb.login()\n",
        "\n",
        "# Option 2: Programmatic login (uncomment and add your key)\n",
        "# wandb.login(key='your-api-key-here')\n",
        "\n",
        "print(\"\\u2713 wandb configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o7AgSBtLcvo"
      },
      "source": [
        "## 6. Training Configuration\n",
        "\n",
        "Set training parameters. Modify these as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X6zQcf9Lcvp",
        "outputId": "5c81aa76-9f4d-4448-db32-c91fc3dd6f9f"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "CONFIG_IDX = 3          # Model config (3 = JCM800 NAM model)\n",
        "MAX_EPOCHS = 100        # Number of epochs to train\n",
        "USE_WANDB = True        # Enable wandb logging\n",
        "LOG_EVERY_N_STEPS = 10  # Log every 10 steps (adjust as needed)\n",
        "\n",
        "print(f\"Training configuration:\")\n",
        "print(f\"  Config index: {CONFIG_IDX}\")\n",
        "print(f\"  Max epochs: {MAX_EPOCHS}\")\n",
        "print(f\"  wandb logging: {USE_WANDB}\")\n",
        "print(f\"  Log every N steps: {LOG_EVERY_N_STEPS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08MLM5LFLcvp"
      },
      "source": [
        "## 7. Run Training\n",
        "\n",
        "Execute the training script. Progress will stream to this notebook.\n",
        "\n",
        "**Expected time:** ~2-3 hours for 100 epochs on T4 GPU\n",
        "\n",
        "**Monitoring:**\n",
        "- Live metrics visible in this notebook\n",
        "- Full dashboard at wandb.ai\n",
        "- Checkpoints auto-save to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWFdBXqkLcvq",
        "outputId": "a6070cb1-36b3-4556-ba71-543e9800be64"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Ensure we're in the repo directory\n",
        "os.chdir('/content/dafx25_antialiasing_neural')\n",
        "\n",
        "# Build command\n",
        "cmd_parts = [\n",
        "    'python train.py',\n",
        "    f'--config {CONFIG_IDX}',\n",
        "    f'--max_epochs {MAX_EPOCHS}',\n",
        "]\n",
        "\n",
        "if USE_WANDB:\n",
        "    cmd_parts.append('--wandb')\n",
        "else:\n",
        "    cmd_parts.append('--no-wandb')\n",
        "\n",
        "cmd = ' '.join(cmd_parts)\n",
        "\n",
        "print(f\"Executing: {cmd}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Run training (this will take a while)\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMbr3yEPLcvq"
      },
      "source": [
        "## 8. Post-Training\n",
        "\n",
        "After training completes, checkpoints are in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGrkagOHLcvq"
      },
      "outputs": [],
      "source": [
        "# List saved checkpoints\n",
        "import os\n",
        "import glob\n",
        "\n",
        "checkpoints_base = '/content/drive/MyDrive/AA_Neural/checkpoints'\n",
        "\n",
        "# Find all checkpoint versions\n",
        "versions = sorted(glob.glob(f'{checkpoints_base}/version_*'))\n",
        "\n",
        "if versions:\n",
        "    latest_version = versions[-1]\n",
        "    print(f\"Found {len(versions)} training run(s)\")\n",
        "    print(f\"\\nLatest run: {latest_version}\")\n",
        "\n",
        "    # List checkpoints in latest run\n",
        "    checkpoints = glob.glob(f'{latest_version}/checkpoints/*.ckpt')\n",
        "    if checkpoints:\n",
        "        print(f\"\\nCheckpoints ({len(checkpoints)}):\")\n",
        "        for ckpt in sorted(checkpoints):\n",
        "            size_mb = os.path.getsize(ckpt) / (1024*1024)\n",
        "            print(f\"  {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n",
        "\n",
        "    # Check for best model export\n",
        "    best_export = f'{latest_version}/best_export'\n",
        "    if os.path.exists(best_export):\n",
        "        print(f\"\\n✓ Best model exported to: {best_export}\")\n",
        "        exported_files = glob.glob(f'{best_export}/*')\n",
        "        for f in exported_files:\n",
        "            print(f\"  {os.path.basename(f)}\")\n",
        "else:\n",
        "    print(\"No checkpoints found. Training may not have completed.\")\n",
        "\n",
        "print(f\"\\nAll results saved to Google Drive: {checkpoints_base}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
